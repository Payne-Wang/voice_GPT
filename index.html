<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>智能语音助手</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdn.jsdelivr.net/npm/axios/dist/axios.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/dompurify/dist/purify.min.js"></script>
    <style>
        .markdown-body {
            background-color: #f6f8fa;
            border-radius: 6px;
            padding: 16px;
            font-size: 14px;
            line-height: 1.5;
            color: #24292e;
            max-height: 400px;
            overflow: auto;
        }
        .markdown-body pre {
            background-color: #f0f0f0;
            border-radius: 3px;
            padding: 16px;
            overflow-x: auto;
        }
        .markdown-body code {
            background-color: #f0f0f0;
            border-radius: 3px;
            padding: 0.2em 0.4em;
            font-size: 85%;
        }
        @keyframes pulse {
            0% { transform: scale(1); }
            50% { transform: scale(1.1); }
            100% { transform: scale(1); }
        }
        .speaker-active {
            animation: pulse 1s infinite;
            background-color: #48bb78 !important;
            color: white !important;
        }
    </style>
</head>
<body class="bg-gray-100 min-h-screen">
    <div class="container mx-auto px-4 py-8 flex flex-col h-screen max-w-4xl">
        <div class="bg-white shadow-md rounded-lg p-4 mb-4">
            <div class="flex flex-col gap-2">
                <div class="flex flex-col sm:flex-row gap-2">
                    <input id="baseUrlInput" type="text" placeholder="API Base URL (默认: https://gptproxy.openai520.top)" class="border border-gray-300 rounded p-2 flex-grow" />
                    <input id="apiKeyInput" type="password" placeholder="输入API Key" class="border border-gray-300 rounded p-2 flex-grow" />
                </div>
                <div class="flex flex-col sm:flex-row gap-2">
                    <select id="modelSelect" class="border border-gray-300 rounded p-2 flex-grow">
                        <!-- 模型选项将在这里动态添加 -->
                    </select>
                    <select id="ttsService" class="border border-gray-300 rounded p-2 flex-grow">
                        <option value="openai">OpenAI TTS</option>
                        <option value="edge">Edge TTS</option>
                    </select>
                </div>
                <div id="openaiTtsOptions" class="flex flex-col sm:flex-row gap-2">
                    <select id="openaiVoiceSelect" class="border border-gray-300 rounded p-2 flex-grow">
                        <!-- OpenAI 音色选项将在这里动态添加 -->
                    </select>
                    <div class="flex items-center flex-grow">
                        <input id="openaiTtsSpeed" type="range" min="0.5" max="2" step="0.1" value="1" class="w-full" />
                        <span id="openaiTtsSpeedValue" class="ml-2 whitespace-nowrap">TTS速度: 1</span>
                    </div>
                </div>
                <div id="edgeTtsOptions" class="flex flex-col gap-2" style="display: none;">
                    <select id="edgeVoiceSelect" class="border border-gray-300 rounded p-2">
                        <!-- Edge 音色选项将在这里动态添加 -->
                    </select>
                    <div class="flex items-center">
                        <input id="edgeTtsSpeed" type="range" min="0.5" max="2" step="0.1" value="1" class="w-full" />
                        <span id="edgeTtsSpeedValue" class="ml-2 whitespace-nowrap">TTS速度: 1</span>
                    </div>
                </div>
            </div>
        </div>
        <div id="chatContainer" class="flex-grow overflow-y-auto bg-white shadow-md rounded-lg p-4 mb-4">
            <!-- 对话内容将在这里动态添加 -->
        </div>
        <div class="bg-white shadow-md rounded-lg p-4">
            <div class="flex flex-col sm:flex-row items-center gap-2">
                <button id="micButton" class="bg-blue-500 text-white rounded-full p-2 hover:bg-blue-600 w-full sm:w-auto mb-2 sm:mb-0">
                    <svg xmlns="http://www.w3.org/2000/svg" class="h-6 w-6 mx-auto" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 11a7 7 0 01-7 7m0 0a7 7 0 01-7-7m7 7v4m0 0H8m4 0h4m-4-8a3 3 0 01-3-3V5a3 3 0 116 0v6a3 3 0 01-3 3z" />
                    </svg>
                </button>
                <input id="userInput" type="text" placeholder="输入你的消息..." 
                       class="border border-gray-300 rounded-lg p-2 w-full focus:outline-none focus:ring-2 focus:ring-blue-500" />
                <div class="flex w-full sm:w-auto gap-2">
                    <button id="sendButton" class="bg-blue-500 text-white rounded-lg p-2 hover:bg-blue-600 flex-grow sm:flex-grow-0">发送</button>
                    <button id="clearButton" class="bg-red-500 text-white rounded-lg p-2 hover:bg-red-600 flex-grow sm:flex-grow-0">清屏</button>
                </div>
            </div>
        </div>
    </div>

    <script>
        let API_BASE_URL = 'https://gptproxy.openai520.top';
        let currentAudio = null;
        let currentAudioSource = null;
        let currentSpeakerButton = null;
        let isPlayingAudio = false;
        const baseUrlInput = document.getElementById('baseUrlInput');
        const apiKeyInput = document.getElementById('apiKeyInput');
        const modelSelect = document.getElementById('modelSelect');
        const ttsService = document.getElementById('ttsService');
        const openaiTtsOptions = document.getElementById('openaiTtsOptions');
        const edgeTtsOptions = document.getElementById('edgeTtsOptions');
        const openaiVoiceSelect = document.getElementById('openaiVoiceSelect');
        const edgeVoiceSelect = document.getElementById('edgeVoiceSelect');
        const openaiTtsSpeed = document.getElementById('openaiTtsSpeed');
        const edgeTtsSpeed = document.getElementById('edgeTtsSpeed');
        const openaiTtsSpeedValue = document.getElementById('openaiTtsSpeedValue');
        const edgeTtsSpeedValue = document.getElementById('edgeTtsSpeedValue');
        const chatContainer = document.getElementById('chatContainer');
        const userInput = document.getElementById('userInput');
        const sendButton = document.getElementById('sendButton');
        const micButton = document.getElementById('micButton');
        const clearButton = document.getElementById('clearButton');

        let isRecording = false;
        let mediaRecorder;
        let audioChunks = [];
        let conversationHistory = [];

        const allowedModels = [
            'gpt-4o-mini',
            'gpt-3.5-turbo-16k',
            'claude-3-haiku-20240307',
            'gemini-1.5-flash-001',
            'claude-3-5-sonnet-20240620'
        ];

        const openaiVoices = [
            { name: "Alloy", value: "alloy" },
            { name: "Echo", value: "echo" },
            { name: "Fable", value: "fable" },
            { name: "Onyx", value: "onyx" },
            { name: "Nova", value: "nova" },
            { name: "Shimmer", value: "shimmer" }
        ];

        function saveSettings() {
            localStorage.setItem('baseUrl', baseUrlInput.value);
            localStorage.setItem('apiKey', apiKeyInput.value);
            localStorage.setItem('ttsService', ttsService.value);
            localStorage.setItem('openaiVoice', openaiVoiceSelect.value);
            localStorage.setItem('edgeVoice', edgeVoiceSelect.value);
            localStorage.setItem('openaiTtsSpeed', openaiTtsSpeed.value);
            localStorage.setItem('edgeTtsSpeed', edgeTtsSpeed.value);
        }

        function loadSettings() {
            const savedBaseUrl = localStorage.getItem('baseUrl');
            const savedApiKey = localStorage.getItem('apiKey');
            const savedTtsService = localStorage.getItem('ttsService');
            const savedOpenaiVoice = localStorage.getItem('openaiVoice');
            const savedEdgeVoice = localStorage.getItem('edgeVoice');
            const savedOpenaiTtsSpeed = localStorage.getItem('openaiTtsSpeed');
            const savedEdgeTtsSpeed = localStorage.getItem('edgeTtsSpeed');
            
            if (savedBaseUrl) {
                baseUrlInput.value = savedBaseUrl;
                API_BASE_URL = savedBaseUrl;
            }
            
            if (savedApiKey) {
                apiKeyInput.value = savedApiKey;
                fetchModels();
            }

            if (savedTtsService) {
                ttsService.value = savedTtsService;
                updateTtsOptions();
            }

            if (savedOpenaiVoice) openaiVoiceSelect.value = savedOpenaiVoice;
            if (savedEdgeVoice) edgeVoiceSelect.value = savedEdgeVoice;
            if (savedOpenaiTtsSpeed) {
                openaiTtsSpeed.value = savedOpenaiTtsSpeed;
                updateTTSSpeed('openai');
            }
            if (savedEdgeTtsSpeed) {
                edgeTtsSpeed.value = savedEdgeTtsSpeed;
                updateTTSSpeed('edge');
            }
        }

        baseUrlInput.addEventListener('input', updateBaseUrl);
        sendButton.addEventListener('click', sendMessage);
        userInput.addEventListener('keypress', (e) => e.key === 'Enter' && sendMessage());
        micButton.addEventListener('click', toggleRecording);
        clearButton.addEventListener('click', clearChat);
        openaiTtsSpeed.addEventListener('input', () => updateTTSSpeed('openai'));
        edgeTtsSpeed.addEventListener('input', () => updateTTSSpeed('edge'));
        apiKeyInput.addEventListener('input', debounce(() => {
            fetchModels();
            saveSettings();
        }, 500));
        ttsService.addEventListener('change', updateTtsOptions);

        function updateBaseUrl() {
            const newBaseUrl = baseUrlInput.value.trim();
            API_BASE_URL = newBaseUrl || 'https://gptproxy.openai520.top';
            saveSettings();
        }

        function debounce(func, wait) {
            let timeout;
            return function executedFunction(...args) {
                const later = () => {
                    clearTimeout(timeout);
                    func(...args);
                };
                clearTimeout(timeout);
                timeout = setTimeout(later, wait);
            };
        }

        function updateTTSSpeed(service) {
            if (service === 'openai') {
                openaiTtsSpeedValue.textContent = `TTS速度: ${openaiTtsSpeed.value}`;
            } else {
                edgeTtsSpeedValue.textContent = `TTS速度: ${edgeTtsSpeed.value}`;
            }
            saveSettings();
        }

        function updateTtsOptions() {
            if (ttsService.value === 'openai') {
                openaiTtsOptions.style.display = 'flex';
                edgeTtsOptions.style.display = 'none';
            } else {
                openaiTtsOptions.style.display = 'none';
                edgeTtsOptions.style.display = 'flex';
            }
            updateVoiceOptions();
            saveSettings();
        }

        function updateVoiceOptions() {
            if (ttsService.value === 'openai') {
                openaiVoiceSelect.innerHTML = '';
                openaiVoices.forEach(voice => {
                    const option = document.createElement('option');
                    option.value = voice.value;
                    option.textContent = voice.name;
                    openaiVoiceSelect.appendChild(option);
                });
            } else {
                edgeVoiceSelect.innerHTML = '';
                const voices = speechSynthesis.getVoices();
                voices.forEach((voice, index) => {
                    if (voice.lang.startsWith('zh') || voice.lang.startsWith('en')) {
                        const option = document.createElement('option');
                        option.value = index;
                        option.textContent = `${voice.name} (${voice.lang})`;
                        edgeVoiceSelect.appendChild(option);
                    }
                });
            }
        }

        async function fetchModels() {
            const apiKey = apiKeyInput.value.trim();
            if (!apiKey) {
                modelSelect.innerHTML = '<option value="">请先输入 API Key</option>';
                return;
            }

            try {
                const response = await axios.get(`${API_BASE_URL}/v1/models`, {
                    headers: {
                        'Authorization': `Bearer ${apiKey}`
                    }
                });
                const models = response.data.data
                    .filter(model => allowedModels.includes(model.id))
                    .map(model => model.id);
                populateModelSelect(models);
            } catch (error) {
                console.error('Error fetching models:', error);
                showNotification('获取模型列表失败', 'error');
                modelSelect.innerHTML = '<option value="">获取模型失败</option>';
            }
        }

        function populateModelSelect(models) {
            modelSelect.innerHTML = '';
            if (models.length === 0) {
                modelSelect.innerHTML = '<option value="">没有可用的模型</option>';
                return;
            }
            models.forEach(model => {
                const option = document.createElement('option');
                option.value = model;
                option.textContent = model;
                modelSelect.appendChild(option);
            });
        }

        function toggleRecording() {
            if (isRecording) {
                stopRecording();
            } else {
                startRecording();
            }
        }

                async function startRecording() {
            stopAllAudio();
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                mediaRecorder = new MediaRecorder(stream);
                audioChunks = [];

                mediaRecorder.ondataavailable = (event) => {
                    audioChunks.push(event.data);
                };

                mediaRecorder.onstop = async () => {
                    const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
                    await transcribeAudio(audioBlob);
                };

                mediaRecorder.start();
                isRecording = true;
                micButton.classList.remove('bg-blue-500', 'hover:bg-blue-600');
                micButton.classList.add('bg-red-500', 'hover:bg-red-600');
                showNotification('麦克风已开启');
            } catch (error) {
                console.error('Error accessing microphone:', error);
                showNotification('无法访问麦克风', 'error');
            }
        }

        function stopRecording() {
            if (mediaRecorder && isRecording) {
                mediaRecorder.stop();
                isRecording = false;
                micButton.classList.remove('bg-red-500', 'hover:bg-red-600');
                micButton.classList.add('bg-blue-500', 'hover:bg-blue-600');
                showNotification('麦克风已关闭');
            }
        }

        function showNotification(message, type = 'info') {
            const notification = document.createElement('div');
            notification.textContent = message;
            notification.className = `fixed top-4 right-4 p-2 rounded-lg text-white ${type === 'error' ? 'bg-red-500' : 'bg-green-500'}`;
            document.body.appendChild(notification);
            setTimeout(() => notification.remove(), 3000);
        }

        async function transcribeAudio(audioBlob) {
            const formData = new FormData();
            formData.append('file', audioBlob, 'audio.wav');
            formData.append('model', 'whisper-1');

            try {
                const response = await axios.post(`${API_BASE_URL}/v1/audio/transcriptions`, formData, {
                    headers: {
                        'Authorization': `Bearer ${apiKeyInput.value}`,
                        'Content-Type': 'multipart/form-data'
                    }
                });

                userInput.value = response.data.text;
                sendMessage();
            } catch (error) {
                console.error('Error transcribing audio:', error);
                showNotification('音频转写失败', 'error');
            }
        }

        async function sendMessage() {
            const message = userInput.value.trim();
            if (!message) return;

            appendMessage('user', message);
            userInput.value = '';

            const apiKey = apiKeyInput.value.trim();
            if (!apiKey) {
                appendMessage('assistant', '请先输入 API Key');
                return;
            }

            const selectedModel = modelSelect.value;
            if (!selectedModel) {
                appendMessage('assistant', '请选择一个模型');
                return;
            }

            conversationHistory.push({ role: 'user', content: message });

            try {
                const response = await axios.post(`${API_BASE_URL}/v1/chat/completions`, {
                    model: selectedModel,
                    messages: conversationHistory
                }, {
                    headers: {
                        'Authorization': `Bearer ${apiKey}`,
                        'Content-Type': 'application/json'
                    }
                });

                const assistantMessage = response.data.choices[0].message.content;
                const speakerButton = appendMessage('assistant', assistantMessage);
                conversationHistory.push({ role: 'assistant', content: assistantMessage });

                // 在文字消息完全返回后，开始播放语音
                await generateSpeech(assistantMessage, speakerButton);
            } catch (error) {
                console.error('Error sending message:', error);
                appendMessage('assistant', '发送消息时出错');
            }
        }

        function appendMessage(role, content) {
            const messageDiv = document.createElement('div');
            messageDiv.className = `mb-4 ${role === 'user' ? 'text-right' : 'text-left'}`;

            const contentDiv = document.createElement('div');
            contentDiv.className = `inline-block p-2 rounded-lg ${role === 'user' ? 'bg-blue-200' : 'bg-gray-200'}`;

            if (role === 'assistant') {
                contentDiv.innerHTML = DOMPurify.sanitize(marked.parse(content));
                contentDiv.classList.add('markdown-body');
            } else {
                contentDiv.textContent = content;
            }

            messageDiv.appendChild(contentDiv);

            let speakerButton;
            if (role === 'assistant') {
                speakerButton = document.createElement('button');
                speakerButton.innerHTML = '🔊';
                speakerButton.className = 'ml-2 p-2 bg-gray-300 rounded-full hover:bg-gray-400 focus:outline-none';
                speakerButton.onclick = () => toggleSpeech(content, speakerButton);
                messageDiv.appendChild(speakerButton);
            }

            chatContainer.appendChild(messageDiv);
            chatContainer.scrollTop = chatContainer.scrollHeight;

            return speakerButton;
        }

        function toggleSpeech(text, speakerButton) {
            if (isPlayingAudio && currentSpeakerButton === speakerButton) {
                stopAllAudio();
            } else {
                generateSpeech(text, speakerButton);
            }
        }

        async function generateSpeech(text, speakerButton) {
            stopAllAudio();
            
            const apiKey = apiKeyInput.value.trim();
            if (!apiKey && ttsService.value === 'openai') {
                showNotification('请先输入 API Key', 'error');
                return;
            }

            try {
                if (ttsService.value === 'openai') {
                    const response = await axios.post(`${API_BASE_URL}/v1/audio/speech`, {
                        model: 'tts-1',
                        input: text,
                        voice: openaiVoiceSelect.value,
                        speed: parseFloat(openaiTtsSpeed.value)
                    }, {
                        headers: {
                            'Authorization': `Bearer ${apiKey}`,
                            'Content-Type': 'application/json'
                        },
                        responseType: 'arraybuffer'
                    });
                    const audioBlob = new Blob([response.data], { type: 'audio/mpeg' });
                    playAudio(audioBlob, speakerButton);
                } else {
                    // Edge TTS (Web Speech API)
                    const utterance = new SpeechSynthesisUtterance(text);
                    const voices = speechSynthesis.getVoices();
                    utterance.voice = voices[parseInt(edgeVoiceSelect.value)];
                    utterance.rate = parseFloat(edgeTtsSpeed.value);
                    
                    utterance.onstart = () => {
                        isPlayingAudio = true;
                        updateSpeakerButtonState(speakerButton, true);
                    };
                    utterance.onend = () => {
                        isPlayingAudio = false;
                        updateSpeakerButtonState(speakerButton, false);
                    };
                    utterance.onerror = () => {
                        isPlayingAudio = false;
                        updateSpeakerButtonState(speakerButton, false);
                    };

                    speechSynthesis.speak(utterance);
                    currentAudio = utterance;
                    currentSpeakerButton = speakerButton;
                }
            } catch (error) {
                console.error('Error generating speech:', error);
                showNotification('生成语音失败', 'error');
            }
        }

        function playAudio(audioBlob, speakerButton) {
            const audioUrl = URL.createObjectURL(audioBlob);
            const audio = new Audio(audioUrl);

            audio.onplay = () => {
                isPlayingAudio = true;
                updateSpeakerButtonState(speakerButton, true);
            };

            audio.onended = () => {
                isPlayingAudio = false;
                updateSpeakerButtonState(speakerButton, false);
                URL.revokeObjectURL(audioUrl);
            };

            audio.onerror = () => {
                isPlayingAudio = false;
                updateSpeakerButtonState(speakerButton, false);
                URL.revokeObjectURL(audioUrl);
            };

            currentAudio = audio;
            currentAudioSource = audioUrl;
            currentSpeakerButton = speakerButton;

            audio.play();
        }

        function updateSpeakerButtonState(button, isPlaying) {
            if (isPlaying) {
                button.classList.add('speaker-active');
            } else {
                button.classList.remove('speaker-active');
            }
        }

        function stopAllAudio() {
            if (currentAudio) {
                if (ttsService.value === 'openai') {
                    currentAudio.pause();
                    currentAudio.currentTime = 0;
                } else {
                    speechSynthesis.cancel();
                }
            }
            if (currentAudioSource) {
                URL.revokeObjectURL(currentAudioSource);
            }
            if (currentSpeakerButton) {
                updateSpeakerButtonState(currentSpeakerButton, false);
            }
            isPlayingAudio = false;
            currentAudio = null;
            currentAudioSource = null;
            currentSpeakerButton = null;
        }

        function clearChat() {
            chatContainer.innerHTML = '';
            conversationHistory = [];
            stopAllAudio();
        }

        // 初始化
        loadSettings();
        fetchModels();
        updateTtsOptions();

        // 确保在语音列表加载完成后更新选项
        if (speechSynthesis.onvoiceschanged !== undefined) {
            speechSynthesis.onvoiceschanged = updateVoiceOptions;
        }
    </script>
</body>
</html>

